"""
AI Code Audit System

A comprehensive AI-powered code security audit system that provides
intelligent analysis of source code for security vulnerabilities,
code quality issues, and best practice violations.
"""

__version__ = "0.1.0"
__author__ = "AI Code Audit Team"
__email__ = "team@example.com"

from ai_code_audit.core.models import (
    ProjectInfo,
    FileInfo,
    Module,
    SecurityFinding,
    AuditResult,
    AuditContext,
)

__all__ = [
    "ProjectInfo",
    "FileInfo",
    "Module",
    "SecurityFinding",
    "AuditResult",
    "AuditContext",
    "audit_project",
]

# ç®€åŒ–çš„ä¸»å…¥å£ - ç›´æ¥ä½¿ç”¨æ ¸å¿ƒç»„ä»¶ï¼Œé¿å…å¤æ‚ä¾èµ–
async def audit_project(
    project_path: str,
    output_file: str = None,
    template: str = "security_audit_chinese",
    max_files: int = 0,
    show_filter_stats: bool = True,
    filter_level: str = "strict"
):
    """
    ç®€åŒ–çš„é¡¹ç›®å®¡è®¡å…¥å£

    Args:
        project_path: é¡¹ç›®è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        template: å®¡è®¡æ¨¡æ¿
        max_files: æœ€å¤§æ–‡ä»¶æ•° (0=æ— é™åˆ¶)
        show_filter_stats: æ˜¾ç¤ºè¿‡æ»¤ç»Ÿè®¡
        filter_level: è¿‡æ»¤çº§åˆ« (strict/moderate/lenient)
    """
    from rich.console import Console
    from .core.config import ConfigManager
    from .core.file_filter import FileFilter
    from .analysis.project_analyzer import ProjectAnalyzer
    from .llm.manager import LLMManager
    from .templates.advanced_templates import AdvancedTemplateManager
    import json
    from datetime import datetime
    from pathlib import Path

    console = Console()

    try:
        console.print(f"ğŸ” å¼€å§‹å®¡è®¡é¡¹ç›®: {project_path}")
        console.print(f"ğŸ“ ä½¿ç”¨æ¨¡æ¿: {template}")

        # 1. åŠ è½½é…ç½®
        config_manager = ConfigManager()
        config = config_manager.load_config()

        # 2. åˆ†æé¡¹ç›®ç»“æ„
        console.print("ğŸ“‹ åˆ†æé¡¹ç›®ç»“æ„...")
        analyzer = ProjectAnalyzer()
        project_info = await analyzer.analyze_project(project_path, save_to_db=False)
        console.print(f"âœ… å‘ç° {len(project_info.files)} ä¸ªæ–‡ä»¶")

        # 3. åº”ç”¨æ–‡ä»¶è¿‡æ»¤
        if show_filter_stats:
            console.print("ğŸ” åº”ç”¨æ™ºèƒ½æ–‡ä»¶è¿‡æ»¤...")
            file_filter = FileFilter(config.file_filtering, project_path)
            file_paths = [str(f.path) for f in project_info.files]
            filtered_files, filter_stats = file_filter.filter_files(file_paths)

            console.print(f"ğŸ“Š æ–‡ä»¶è¿‡æ»¤ç»Ÿè®¡:")
            console.print(f"â€¢ æ‰«ææ–‡ä»¶æ€»æ•°: {len(file_paths)}")
            console.print(f"â€¢ å®¡è®¡æ–‡ä»¶æ•°: {len(filtered_files)}")
            console.print(f"â€¢ è¿‡æ»¤æ‰æ–‡ä»¶æ•°: {len(file_paths) - len(filtered_files)}")
            console.print(f"â€¢ è¿‡æ»¤æ•ˆç‡: {((len(file_paths) - len(filtered_files)) / len(file_paths) * 100):.1f}%")

            # æ›´æ–°é¡¹ç›®ä¿¡æ¯ï¼Œåªä¿ç•™è¿‡æ»¤åçš„æ–‡ä»¶
            filtered_file_objs = [f for f in project_info.files if str(f.path) in filtered_files]
            project_info.files = filtered_file_objs[:max_files] if max_files and max_files > 0 else filtered_file_objs
        else:
            # ç›´æ¥é™åˆ¶æ–‡ä»¶æ•°é‡
            if max_files and max_files > 0:
                project_info.files = project_info.files[:max_files]

        console.print(f"ğŸ¯ å°†å®¡è®¡ {len(project_info.files)} ä¸ªæ–‡ä»¶")

        # 4. åˆå§‹åŒ–LLMå’Œæ¨¡æ¿
        console.print("ğŸ¤– åˆå§‹åŒ–AIæ¨¡å‹...")
        # åˆ›å»ºå…¼å®¹çš„LLMé…ç½®ï¼ˆä½¿ç”¨LLMManageræœŸæœ›çš„æ ¼å¼ï¼‰
        llm_config_dict = {
            'llm': {},
            'performance': {
                'max_parallel_requests': 5,
                'request_timeout': 60,
                'retry_attempts': 3,
            }
        }

        # æ·»åŠ qwené…ç½®
        if config.llm.qwen and config.llm.qwen.enabled:
            llm_config_dict['llm']['qwen'] = {
                'api_key': config.llm.qwen.api_key,
                'base_url': config.llm.qwen.base_url,
                'enabled': config.llm.qwen.enabled,
                'priority': config.llm.qwen.priority,
                'max_requests_per_minute': config.llm.qwen.max_requests_per_minute,
                'cost_weight': config.llm.qwen.cost_weight,
                'performance_weight': config.llm.qwen.performance_weight,
            }

        # æ·»åŠ kimié…ç½®
        if config.llm.kimi and config.llm.kimi.enabled:
            llm_config_dict['llm']['kimi'] = {
                'api_key': config.llm.kimi.api_key,
                'base_url': config.llm.kimi.base_url,
                'enabled': config.llm.kimi.enabled,
                'priority': config.llm.kimi.priority,
                'max_requests_per_minute': config.llm.kimi.max_requests_per_minute,
                'cost_weight': config.llm.kimi.cost_weight,
                'performance_weight': config.llm.kimi.performance_weight,
            }

        llm_manager = LLMManager(llm_config_dict)
        # è®¾ç½®é¡¹ç›®è·¯å¾„ï¼Œå¯ç”¨è·¨æ–‡ä»¶åˆ†æ
        llm_manager.set_project_path(project_path)
        template_manager = AdvancedTemplateManager()

        # 5. æ‰§è¡Œç®€åŒ–çš„å®¡è®¡æµç¨‹
        console.print("ğŸ” å¼€å§‹å®‰å…¨å®¡è®¡...")
        results = {
            "project_path": project_path,
            "template": template,
            "total_files": len(project_info.files),
            "findings": [],
            "summary": {},
            "timestamp": str(datetime.now())
        }

        # ç®€å•çš„æ–‡ä»¶åˆ†æå¾ªç¯
        for i, file_info in enumerate(project_info.files):
            file_name = Path(file_info.path).name if hasattr(file_info.path, 'name') else Path(str(file_info.path)).name
            console.print(f"åˆ†æ {i+1}/{len(project_info.files)}: {file_name}")

            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                file_path = str(file_info.path)
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                if not Path(file_path).is_absolute():
                    full_path = Path(project_path) / file_path
                else:
                    full_path = Path(file_path)

                with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()

                # è·å–æ¨¡æ¿æç¤ºè¯
                template_obj = template_manager.get_template(template)
                if template_obj:
                    # æ„å»ºåˆ†æè¯·æ±‚
                    analysis_prompt = f"{template_obj.system_prompt}\n\næ–‡ä»¶è·¯å¾„: {file_info.path}\n\nä»£ç å†…å®¹:\n{content}"

                    # è°ƒç”¨LLMåˆ†æ
                    try:
                        console.print(f"  ğŸ¤– æ­£åœ¨åˆ†æ {file_info.language} ä»£ç ...")
                        response = await llm_manager.analyze_code(
                            code=content,
                            file_path=str(file_info.path),
                            language=file_info.language,
                            template=template
                        )
                        console.print(f"  ğŸ“Š LLMå“åº”: success={response.get('success', False)}")

                        if response and response.get('success') and response.get('findings'):
                            findings_count = len(response['findings'])
                            console.print(f"  ğŸš¨ å‘ç° {findings_count} ä¸ªå®‰å…¨é—®é¢˜")

                            for finding in response['findings']:
                                # ç¡®ä¿findingåŒ…å«å¿…è¦çš„å­—æ®µ
                                finding['file'] = str(file_info.path)
                                finding['language'] = file_info.language
                                results["findings"].append(finding)
                        elif response and not response.get('success'):
                            # LLMåˆ†æå¤±è´¥
                            console.print(f"  âš ï¸  LLMåˆ†æå¤±è´¥: {response.get('error', 'Unknown error')}")
                        else:
                            # å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œè®°å½•ä¸€ä¸ªç©ºç»“æœ
                            console.print(f"  âœ… æœªå‘ç°å®‰å…¨é—®é¢˜")

                    except Exception as llm_error:
                        console.print(f"  âš ï¸  LLMåˆ†æå¤±è´¥: {llm_error}")
                        # æ·»åŠ é”™è¯¯è®°å½•
                        error_finding = {
                            "file": str(file_info.path),
                            "language": file_info.language,
                            "issues": [f"LLMåˆ†æå¤±è´¥: {str(llm_error)}"],
                            "severity": "info",
                            "type": "analysis_error"
                        }
                        results["findings"].append(error_finding)

            except Exception as e:
                console.print(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {file_info.path}: {e}")
                continue

        # 6. ç”Ÿæˆæ‘˜è¦
        results["summary"] = {
            "total_findings": len(results["findings"]),
            "files_analyzed": len(project_info.files),
            "completion_status": "success"
        }

        # 7. ä¿å­˜ç»“æœ
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            console.print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        console.print("ğŸ‰ å®¡è®¡å®Œæˆ!")
        return results

    except Exception as e:
        console.print(f"âŒ å®¡è®¡å¤±è´¥: {e}")
        raise
