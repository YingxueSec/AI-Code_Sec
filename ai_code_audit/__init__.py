"""
AI Code Audit System

A comprehensive AI-powered code security audit system that provides
intelligent analysis of source code for security vulnerabilities,
code quality issues, and best practice violations.
"""

__version__ = "0.1.0"
__author__ = "AI Code Audit Team"
__email__ = "team@example.com"

from ai_code_audit.core.models import (
    ProjectInfo,
    FileInfo,
    Module,
    SecurityFinding,
    AuditResult,
    AuditContext,
)

__all__ = [
    "ProjectInfo",
    "FileInfo",
    "Module",
    "SecurityFinding",
    "AuditResult",
    "AuditContext",
    "audit_project",
]

# ç®€åŒ–çš„ä¸»å…¥å£ - ç›´æ¥ä½¿ç”¨æ ¸å¿ƒç»„ä»¶ï¼Œé¿å…å¤æ‚ä¾èµ–
async def audit_project(
    project_path: str,
    output_file: str = None,
    template: str = "security_audit_chinese",
    max_files: int = 0,
    show_filter_stats: bool = True,
    filter_level: str = "strict",
    enable_cross_file: bool = True,
    enable_frontend_opt: bool = True,
    enable_confidence_calc: bool = True,
    enable_filter: bool = True,
    min_confidence: float = 0.3,
    max_confidence: float = 1.0,
    quick_mode: bool = False,
    verbose: bool = False,
    debug: bool = False,
    include_extensions: list = None,
    exclude_extensions: list = None,
    include_paths: list = None,
    exclude_paths: list = None,
    show_timing: bool = True
):
    """
    å®Œæ•´çš„é¡¹ç›®å®¡è®¡å…¥å£ï¼Œæ”¯æŒæ‰€æœ‰åŠŸèƒ½å‚æ•°æ§åˆ¶

    Args:
        project_path: é¡¹ç›®è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        template: å®¡è®¡æ¨¡æ¿
        max_files: æœ€å¤§æ–‡ä»¶æ•° (0=æ— é™åˆ¶)
        show_filter_stats: æ˜¾ç¤ºè¿‡æ»¤ç»Ÿè®¡
        filter_level: è¿‡æ»¤çº§åˆ« (strict/moderate/lenient)
        enable_cross_file: å¯ç”¨è·¨æ–‡ä»¶å…³è”åˆ†æ
        enable_frontend_opt: å¯ç”¨å‰ç«¯ä»£ç ä¼˜åŒ–
        enable_confidence_calc: å¯ç”¨ç½®ä¿¡åº¦è®¡ç®—
        enable_filter: å¯ç”¨æ™ºèƒ½æ–‡ä»¶è¿‡æ»¤
        min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
        max_confidence: æœ€å¤§ç½®ä¿¡åº¦é˜ˆå€¼
        quick_mode: å¿«é€Ÿæ‰«ææ¨¡å¼
        verbose: è¯¦ç»†è¾“å‡ºæ¨¡å¼
        debug: è°ƒè¯•æ¨¡å¼
        include_extensions: åŒ…å«çš„æ–‡ä»¶æ‰©å±•å
        exclude_extensions: æ’é™¤çš„æ–‡ä»¶æ‰©å±•å
        include_paths: åŒ…å«çš„è·¯å¾„æ¨¡å¼
        exclude_paths: æ’é™¤çš„è·¯å¾„æ¨¡å¼
        show_timing: æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
    """
    from rich.console import Console
    from .core.config import ConfigManager
    from .core.file_filter import FileFilter
    from .analysis.project_analyzer import ProjectAnalyzer
    from .llm.manager import LLMManager
    from .templates.advanced_templates import AdvancedTemplateManager
    from .utils.cache import get_cache
    import json
    import time
    from datetime import datetime
    from pathlib import Path

    console = Console()
    llm_manager = None

    # æ—¶é—´ç»Ÿè®¡
    timing_stats = {}
    total_start_time = time.time()

    def log_timing(step_name: str, duration: float):
        """è®°å½•æ—¶é—´ç»Ÿè®¡"""
        timing_stats[step_name] = duration
        if show_timing:
            console.print(f"â±ï¸  {step_name}: {duration:.2f}ç§’")

    try:
        console.print(f"[INFO] å¼€å§‹å®¡è®¡é¡¹ç›®: {project_path}")
        console.print(f"[INFO] ä½¿ç”¨æ¨¡æ¿: {template}")

        # 1. åŠ è½½é…ç½®
        step_start = time.time()
        config_manager = ConfigManager()
        config = config_manager.load_config()
        log_timing("é…ç½®åŠ è½½", time.time() - step_start)

        # 2. åˆ†æé¡¹ç›®ç»“æ„
        console.print("[INFO] åˆ†æé¡¹ç›®ç»“æ„...")
        step_start = time.time()
        analyzer = ProjectAnalyzer()
        # ä¼ é€’æ‰©å±•åè¿‡æ»¤å‚æ•°ç»™é¡¹ç›®åˆ†æå™¨
        project_info = await analyzer.analyze_project(
            project_path,
            save_to_db=False,
            include_extensions=include_extensions,
            exclude_extensions=exclude_extensions,
            include_paths=include_paths,
            exclude_paths=exclude_paths
        )
        log_timing("é¡¹ç›®ç»“æ„åˆ†æ", time.time() - step_start)
        console.print(f"[SUCCESS] å‘ç° {len(project_info.files)} ä¸ªæ–‡ä»¶")

        # 3. åº”ç”¨æ–‡ä»¶è¿‡æ»¤
        step_start = time.time()
        if show_filter_stats:
            console.print("[INFO] åº”ç”¨æ™ºèƒ½æ–‡ä»¶è¿‡æ»¤...")
            # åˆ›å»ºæ–‡ä»¶è¿‡æ»¤å™¨å¹¶ä¼ é€’å‘½ä»¤è¡Œå‚æ•°
            file_filter = FileFilter(
                config.file_filtering,
                project_path,
                include_extensions=include_extensions,
                exclude_extensions=exclude_extensions,
                include_paths=include_paths,
                exclude_paths=exclude_paths
            )
            file_paths = [str(f.path) for f in project_info.files]
            filtered_files, filter_stats = file_filter.filter_files(file_paths)

            console.print(f"[INFO] æ–‡ä»¶è¿‡æ»¤ç»Ÿè®¡:")
            console.print(f"* æ‰«ææ–‡ä»¶æ€»æ•°: {len(file_paths)}")
            console.print(f"* å®¡è®¡æ–‡ä»¶æ•°: {len(filtered_files)}")
            console.print(f"* è¿‡æ»¤æ‰æ–‡ä»¶æ•°: {len(file_paths) - len(filtered_files)}")
            console.print(f"* è¿‡æ»¤æ•ˆç‡: {((len(file_paths) - len(filtered_files)) / len(file_paths) * 100):.1f}%")

            # æ›´æ–°é¡¹ç›®ä¿¡æ¯ï¼Œåªä¿ç•™è¿‡æ»¤åçš„æ–‡ä»¶
            filtered_file_objs = [f for f in project_info.files if str(f.path) in filtered_files]
            project_info.files = filtered_file_objs[:max_files] if max_files and max_files > 0 else filtered_file_objs
        else:
            # ç›´æ¥é™åˆ¶æ–‡ä»¶æ•°é‡
            if max_files and max_files > 0:
                project_info.files = project_info.files[:max_files]

        log_timing("æ–‡ä»¶è¿‡æ»¤", time.time() - step_start)
        console.print(f"[INFO] å°†å®¡è®¡ {len(project_info.files)} ä¸ªæ–‡ä»¶")

        # 4. åˆå§‹åŒ–LLMå’Œæ¨¡æ¿
        console.print("[INFO] åˆå§‹åŒ–AIæ¨¡å‹...")
        step_start = time.time()
        # åˆ›å»ºå…¼å®¹çš„LLMé…ç½®ï¼ˆä½¿ç”¨LLMManageræœŸæœ›çš„æ ¼å¼ï¼‰
        llm_config_dict = {
            'llm': {},
            'performance': {
                'max_parallel_requests': 5,
                'request_timeout': 60,
                'retry_attempts': 3,
            }
        }

        # æ·»åŠ qwené…ç½®
        if config.llm.qwen and config.llm.qwen.enabled:
            llm_config_dict['llm']['qwen'] = {
                'api_key': config.llm.qwen.api_key,
                'base_url': config.llm.qwen.base_url,
                'enabled': config.llm.qwen.enabled,
                'priority': config.llm.qwen.priority,
                'max_requests_per_minute': config.llm.qwen.max_requests_per_minute,
                'cost_weight': config.llm.qwen.cost_weight,
                'performance_weight': config.llm.qwen.performance_weight,
            }

        # æ·»åŠ kimié…ç½®
        if config.llm.kimi and config.llm.kimi.enabled:
            llm_config_dict['llm']['kimi'] = {
                'api_key': config.llm.kimi.api_key,
                'base_url': config.llm.kimi.base_url,
                'enabled': config.llm.kimi.enabled,
                'priority': config.llm.kimi.priority,
                'max_requests_per_minute': config.llm.kimi.max_requests_per_minute,
                'cost_weight': config.llm.kimi.cost_weight,
                'performance_weight': config.llm.kimi.performance_weight,
            }

        llm_manager = LLMManager(llm_config_dict)
        # è®¾ç½®é¡¹ç›®è·¯å¾„ï¼Œå¯ç”¨è·¨æ–‡ä»¶åˆ†æ
        llm_manager.set_project_path(project_path)
        template_manager = AdvancedTemplateManager()
        log_timing("AIæ¨¡å‹åˆå§‹åŒ–", time.time() - step_start)

        # 5. æ‰§è¡Œç®€åŒ–çš„å®¡è®¡æµç¨‹
        console.print("[INFO] å¼€å§‹å®‰å…¨å®¡è®¡...")
        analysis_start_time = time.time()

        results = {
            "project_path": project_path,
            "template": template,
            "total_files": len(project_info.files),
            "findings": [],
            "summary": {},
            "timestamp": str(datetime.now()),
            "timing_stats": {}
        }

        # æ–‡ä»¶åˆ†ææ—¶é—´ç»Ÿè®¡
        file_analysis_times = []
        llm_call_times = []

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
        enable_parallel = len(project_info.files) > 1 and not debug
        max_concurrent = min(3, len(project_info.files))  # æœ€å¤š3ä¸ªå¹¶å‘ï¼Œé¿å…APIé™åˆ¶

        if enable_parallel:
            console.print(f"[INFO] å¯ç”¨å¹¶è¡Œåˆ†æï¼Œæœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
            # å¹¶è¡Œæ–‡ä»¶åˆ†æ
            import asyncio
            semaphore = asyncio.Semaphore(max_concurrent)

            async def analyze_single_file(file_info, index):
                async with semaphore:
                    return await _analyze_file_async(file_info, index, len(project_info.files),
                                                   template_manager, template, llm_manager,
                                                   show_timing, console, project_path)

            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            tasks = [analyze_single_file(file_info, i) for i, file_info in enumerate(project_info.files)]
            analysis_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ç»“æœ
            for result in analysis_results:
                if isinstance(result, Exception):
                    console.print(f"[WARNING] æ–‡ä»¶åˆ†æå¤±è´¥: {result}")
                    continue
                if result:
                    file_time, llm_time, findings = result
                    file_analysis_times.append(file_time)
                    llm_call_times.append(llm_time)
                    results["findings"].extend(findings)
        else:
            # ä¸²è¡Œæ–‡ä»¶åˆ†æå¾ªç¯ï¼ˆè°ƒè¯•æ¨¡å¼æˆ–å•æ–‡ä»¶ï¼‰
            for i, file_info in enumerate(project_info.files):
                file_start_time = time.time()
                file_name = Path(file_info.path).name if hasattr(file_info.path, 'name') else Path(str(file_info.path)).name
                console.print(f"åˆ†æ {i+1}/{len(project_info.files)}: {file_name}")

                try:
                    # è¯»å–æ–‡ä»¶å†…å®¹
                    file_path = str(file_info.path)
                    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                    if not Path(file_path).is_absolute():
                        full_path = Path(project_path) / file_path
                    else:
                        full_path = Path(file_path)

                    with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()

                    # è·å–æ¨¡æ¿æç¤ºè¯
                    template_obj = template_manager.get_template(template)
                    if template_obj:
                        # æ„å»ºåˆ†æè¯·æ±‚
                        analysis_prompt = f"{template_obj.system_prompt}\n\næ–‡ä»¶è·¯å¾„: {file_info.path}\n\nä»£ç å†…å®¹:\n{content}"

                        # è°ƒç”¨LLMåˆ†æ
                        try:
                            console.print(f"  [AI] æ­£åœ¨åˆ†æ {file_info.language} ä»£ç ...")
                            llm_start_time = time.time()
                            response = await llm_manager.analyze_code(
                                code=content,
                                file_path=str(file_info.path),
                                language=file_info.language,
                                template=template
                            )
                            llm_duration = time.time() - llm_start_time
                            llm_call_times.append(llm_duration)

                            if show_timing:
                                console.print(f"  â±ï¸  LLMåˆ†æè€—æ—¶: {llm_duration:.2f}ç§’")
                            console.print(f"  [INFO] LLMå“åº”: success={response.get('success', False)}")

                            if response and response.get('success') and response.get('findings'):
                                findings_count = len(response['findings'])
                                console.print(f"  [ALERT] å‘ç° {findings_count} ä¸ªå®‰å…¨é—®é¢˜")

                                for finding in response['findings']:
                                    # ç¡®ä¿findingåŒ…å«å¿…è¦çš„å­—æ®µ
                                    finding['file'] = str(file_info.path)
                                    finding['language'] = file_info.language
                                    results["findings"].append(finding)
                            elif response and not response.get('success'):
                                # LLMåˆ†æå¤±è´¥
                                console.print(f"  [WARNING] LLMåˆ†æå¤±è´¥: {response.get('error', 'Unknown error')}")
                            else:
                                # å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œè®°å½•ä¸€ä¸ªç©ºç»“æœ
                                console.print(f"  [SUCCESS] æœªå‘ç°å®‰å…¨é—®é¢˜")

                        except Exception as llm_error:
                            console.print(f"  [WARNING] LLMåˆ†æå¤±è´¥: {llm_error}")
                            # æ·»åŠ é”™è¯¯è®°å½•
                            error_finding = {
                                "file": str(file_info.path),
                                "language": file_info.language,
                                "issues": [f"LLMåˆ†æå¤±è´¥: {str(llm_error)}"],
                                "severity": "info",
                                "type": "analysis_error"
                            }
                            results["findings"].append(error_finding)

                except Exception as e:
                    console.print(f"[WARNING] è·³è¿‡æ–‡ä»¶ {file_info.path}: {e}")
                    continue

                # è®°å½•å•ä¸ªæ–‡ä»¶åˆ†ææ—¶é—´
                file_duration = time.time() - file_start_time
                file_analysis_times.append(file_duration)
                if show_timing:
                    console.print(f"  â±ï¸  æ–‡ä»¶åˆ†ææ€»è€—æ—¶: {file_duration:.2f}ç§’")

        # è®°å½•æ€»åˆ†ææ—¶é—´
        total_analysis_time = time.time() - analysis_start_time
        log_timing("ä»£ç åˆ†ææ€»æ—¶é—´", total_analysis_time)

        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache = get_cache()
        cache_stats = cache.get_stats()
        cache_hits = sum(1 for t in llm_call_times if t < 1.0)  # å‡è®¾ç¼“å­˜å‘½ä¸­æ—¶é—´ < 1ç§’
        cache_hit_rate = (cache_hits / len(llm_call_times) * 100) if llm_call_times else 0

        # 6. ç”Ÿæˆæ‘˜è¦å’Œæ—¶é—´ç»Ÿè®¡
        step_start = time.time()

        # è®¡ç®—æ—¶é—´ç»Ÿè®¡
        avg_file_time = sum(file_analysis_times) / len(file_analysis_times) if file_analysis_times else 0
        avg_llm_time = sum(llm_call_times) / len(llm_call_times) if llm_call_times else 0
        total_llm_time = sum(llm_call_times)

        timing_stats.update({
            "ä»£ç åˆ†ææ€»æ—¶é—´": total_analysis_time,
            "LLMè°ƒç”¨æ€»æ—¶é—´": total_llm_time,
            "å¹³å‡æ¯æ–‡ä»¶åˆ†ææ—¶é—´": avg_file_time,
            "å¹³å‡LLMè°ƒç”¨æ—¶é—´": avg_llm_time,
            "LLMè°ƒç”¨æ¬¡æ•°": len(llm_call_times),
            "ç¼“å­˜å‘½ä¸­æ¬¡æ•°": cache_hits,
            "ç¼“å­˜å‘½ä¸­ç‡": cache_hit_rate
        })

        results["summary"] = {
            "total_findings": len(results["findings"]),
            "files_analyzed": len(project_info.files),
            "completion_status": "success"
        }
        results["timing_stats"] = timing_stats
        log_timing("æ‘˜è¦ç”Ÿæˆ", time.time() - step_start)

        # 7. ä¿å­˜ç»“æœ
        step_start = time.time()
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            console.print(f"[SUCCESS] ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

            # ç”ŸæˆmarkdownæŠ¥å‘Š
            try:
                markdown_file = output_file.replace('.json', '_report.md')
                generate_markdown_report(results, markdown_file)
                console.print(f"[INFO] MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {markdown_file}")
            except Exception as report_error:
                console.print(f"[WARNING] ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {report_error}")
        log_timing("ç»“æœä¿å­˜", time.time() - step_start)

        # 8. æ˜¾ç¤ºå®Œæ•´æ—¶é—´ç»Ÿè®¡æŠ¥å‘Š
        total_time = time.time() - total_start_time
        timing_stats["æ€»æ‰§è¡Œæ—¶é—´"] = total_time

        if show_timing:
            console.print("\n" + "="*60)
            console.print("ğŸ“Š æ—¶é—´ç»Ÿè®¡æŠ¥å‘Š")
            console.print("="*60)

            # åˆ†ç±»æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
            time_items = []
            count_items = []
            avg_items = []

            for step, value in timing_stats.items():
                if "æ¬¡æ•°" in step:
                    count_items.append((step, value))
                elif "å¹³å‡" in step:
                    avg_items.append((step, value))
                else:
                    time_items.append((step, value))

            # æ˜¾ç¤ºæ—¶é—´ç±»ç»Ÿè®¡ï¼ˆå¸¦ç™¾åˆ†æ¯”ï¼‰
            for step, duration in time_items:
                if isinstance(duration, (int, float)):
                    percentage = (duration / total_time * 100) if total_time > 0 else 0
                    console.print(f"{step:<20}: {duration:>8.2f}ç§’ ({percentage:>5.1f}%)")

            # æ˜¾ç¤ºå¹³å‡æ—¶é—´ç±»ç»Ÿè®¡ï¼ˆä¸å¸¦ç™¾åˆ†æ¯”ï¼‰
            for step, duration in avg_items:
                if isinstance(duration, (int, float)):
                    console.print(f"{step:<20}: {duration:>8.2f}ç§’")

            # æ˜¾ç¤ºè®¡æ•°ç±»ç»Ÿè®¡ï¼ˆä¸å¸¦ç§’å’Œç™¾åˆ†æ¯”ï¼‰
            for step, count in count_items:
                if "ç‡" in step:
                    console.print(f"{step:<20}: {count:>7.1f}%")
                else:
                    console.print(f"{step:<20}: {count:>8}æ¬¡")

            # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            if cache_stats['total_files'] > 0:
                console.print("-" * 60)
                console.print("ğŸ’¾ ç¼“å­˜ç»Ÿè®¡:")
                console.print(f"{'ç¼“å­˜æ–‡ä»¶æ•°':<20}: {cache_stats['total_files']:>8}ä¸ª")
                console.print(f"{'ç¼“å­˜å¤§å°':<20}: {cache_stats['total_size_mb']:>7.1f}MB")
                console.print(f"{'æœ‰æ•ˆç¼“å­˜':<20}: {cache_stats['valid_files']:>8}ä¸ª")

            console.print("="*60)

        console.print("[SUCCESS] å®¡è®¡å®Œæˆ!")
        return results

    except Exception as e:
        console.print(f"[ERROR] å®¡è®¡å¤±è´¥: {e}")
        raise
    finally:
        if llm_manager:
            await llm_manager.close()


def generate_markdown_report(results, output_file):
    """ç”ŸæˆMarkdownæ ¼å¼çš„å®¡è®¡æŠ¥å‘Š"""
    from datetime import datetime

    # ç»Ÿè®¡æ•°æ®
    total_findings = len(results.get("findings", []))
    files_analyzed = results.get("total_files", 0)

    # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
    severity_counts = {}
    file_findings = {}

    for finding in results.get("findings", []):
        severity = finding.get("severity", "unknown")
        severity_counts[severity] = severity_counts.get(severity, 0) + 1

        file_path = finding.get("file", "unknown")
        if file_path not in file_findings:
            file_findings[file_path] = []
        file_findings[file_path].append(finding)

    # ç”ŸæˆæŠ¥å‘Šå†…å®¹
    report_content = f"""# AIä»£ç å®‰å…¨å®¡è®¡æŠ¥å‘Š

## å®¡è®¡æ¦‚è§ˆ

- **é¡¹ç›®è·¯å¾„**: {results.get('project_path', 'N/A')}
- **å®¡è®¡æ—¶é—´**: {results.get('timestamp', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))}
- **åˆ†ææ–‡ä»¶æ•°**: {files_analyzed}
- **å‘ç°é—®é¢˜æ•°**: {total_findings}

## é—®é¢˜ç»Ÿè®¡

"""

    if severity_counts:
        for severity, count in sorted(severity_counts.items()):
            report_content += f"- **{severity.upper()}**: {count} ä¸ªé—®é¢˜\n"
    else:
        report_content += "- æœªå‘ç°å®‰å…¨é—®é¢˜\n"

    report_content += "\n## è¯¦ç»†å‘ç°\n\n"

    if file_findings:
        for file_path, findings in file_findings.items():
            report_content += f"### æ–‡ä»¶: {file_path}\n\n"

            for i, finding in enumerate(findings, 1):
                severity = finding.get("severity", "unknown").upper()
                line_number = finding.get("line", "N/A")

                report_content += f"#### {i}. {finding.get('type', 'æœªçŸ¥é—®é¢˜')} [{severity}]\n\n"
                report_content += f"- **ä½ç½®**: ç¬¬ {line_number} è¡Œ\n"

                if finding.get("description"):
                    report_content += f"- **æè¿°**: {finding['description']}\n"

                if finding.get("code_snippet") and finding['code_snippet'].strip():
                    report_content += f"\n**ä»£ç ç‰‡æ®µ:**\n```{finding.get('language', '')}\n{finding['code_snippet']}\n```\n"

                if finding.get("recommendation"):
                    report_content += f"\n**å»ºè®®**: {finding['recommendation']}\n"

                report_content += "\n---\n\n"
    else:
        report_content += "æ­å–œï¼æœªå‘ç°ä»»ä½•å®‰å…¨é—®é¢˜ã€‚\n\n"

    report_content += f"""## å®¡è®¡æ€»ç»“

æœ¬æ¬¡å®¡è®¡å…±åˆ†æäº† **{files_analyzed}** ä¸ªæ–‡ä»¶ï¼Œå‘ç°äº† **{total_findings}** ä¸ªæ½œåœ¨é—®é¢˜ã€‚

### å»ºè®®

1. ä¼˜å…ˆå¤„ç†é«˜ä¸¥é‡ç¨‹åº¦çš„å®‰å…¨é—®é¢˜
2. å®šæœŸè¿›è¡Œä»£ç å®‰å…¨å®¡è®¡
3. å»ºç«‹å®‰å…¨ç¼–ç è§„èŒƒ
4. åŠ å¼ºå¼€å‘å›¢é˜Ÿçš„å®‰å…¨æ„è¯†åŸ¹è®­

---

*æŠ¥å‘Šç”±AIä»£ç å®‰å…¨å®¡è®¡ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""

    # å†™å…¥æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report_content)


async def _analyze_file_async(file_info, index, total_files, template_manager, template, llm_manager, show_timing, console, project_path):
    """å¼‚æ­¥åˆ†æå•ä¸ªæ–‡ä»¶"""
    import time
    from pathlib import Path
    from .utils.cache import get_cache

    file_start_time = time.time()
    file_name = Path(file_info.path).name if hasattr(file_info.path, 'name') else Path(str(file_info.path)).name
    console.print(f"åˆ†æ {index+1}/{total_files}: {file_name}")

    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_path = str(file_info.path)
        if not Path(file_path).is_absolute():
            full_path = Path(project_path) / file_path
        else:
            full_path = Path(file_path)

        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        # è·å–æ¨¡æ¿æç¤ºè¯
        template_obj = template_manager.get_template(template)
        if template_obj:
            # æ£€æŸ¥ç¼“å­˜
            cache = get_cache()
            cached_response = cache.get(content, template, file_info.language)

            if cached_response:
                console.print(f"  [CACHE] ä½¿ç”¨ç¼“å­˜ç»“æœ")
                response = cached_response.get('response', {})
                llm_duration = 0.1  # ç¼“å­˜è®¿é—®æ—¶é—´å¾ˆçŸ­
            else:
                # è°ƒç”¨LLMåˆ†æ
                console.print(f"  [AI] æ­£åœ¨åˆ†æ {file_info.language} ä»£ç ...")
                llm_start_time = time.time()
                response = await llm_manager.analyze_code(
                    code=content,
                    file_path=str(file_info.path),
                    language=file_info.language,
                    template=template
                )
                llm_duration = time.time() - llm_start_time

                # ä¿å­˜åˆ°ç¼“å­˜
                if response and response.get('success'):
                    cache.set(content, template, file_info.language, response)

            if show_timing:
                console.print(f"  â±ï¸  LLMåˆ†æè€—æ—¶: {llm_duration:.2f}ç§’")
            console.print(f"  [INFO] LLMå“åº”: success={response.get('success', False)}")

            findings = []
            if response and response.get('success') and response.get('findings'):
                findings_count = len(response['findings'])
                console.print(f"  [ALERT] å‘ç° {findings_count} ä¸ªå®‰å…¨é—®é¢˜")

                for finding in response['findings']:
                    finding['file'] = str(file_info.path)
                    finding['language'] = file_info.language
                    findings.append(finding)
            elif response and not response.get('success'):
                console.print(f"  [WARNING] LLMåˆ†æå¤±è´¥: {response.get('error', 'Unknown error')}")
            else:
                console.print(f"  [SUCCESS] æœªå‘ç°å®‰å…¨é—®é¢˜")

            file_duration = time.time() - file_start_time
            if show_timing:
                console.print(f"  â±ï¸  æ–‡ä»¶åˆ†ææ€»è€—æ—¶: {file_duration:.2f}ç§’")

            return file_duration, llm_duration, findings

    except Exception as e:
        console.print(f"[WARNING] è·³è¿‡æ–‡ä»¶ {file_info.path}: {e}")
        return 0, 0, []
